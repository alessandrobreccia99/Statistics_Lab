cat("The confidence interval for the posterior of the Step prior is",conf(Spost,1/1000, 0.95),"\n")
plot(prob,Spost, col="black",type="l",lwd=2 ,lty=1,xlab = "Probability",ylab = "Probability Density")
abline(v=conf(Spost,1/1000, 0.95), col=c("black", "black"), lty=c(1,1), lwd=c(2, 2))
lines(prob,Jpost, col="red",lty=2,lwd=2)
abline(v=conf(Jpost,1/1000, 0.95), col=c("red", "red"), lty=c(2,2), lwd=c(2, 2))
lines(prob,Fpost, col="blue",lty=3,lwd=2)
abline(v=conf(Fpost,1/1000, 0.95), col=c("blue", "blue"), lty=c(3,3), lwd=c(2, 2))
legend(x="topright",legend=c("Step-Posterior","Jeffrey-Posterior","Uniform-Posterior"), col=c("black","red","blue"),lty=c(1,2,3), cex=0.8)
x <- c("Mean","Lower 95% bound","Upper 95% bound")
jeffrey_post <- c(which.max(Jpost)*1/1000,conf(Jpost,1/1000, 0.95))
uniform_post <- c(which.max(Fpost)*1/1000,conf(Fpost,1/1000, 0.95))
step_post <- c(which.max(Spost)*1/1000,conf(Spost,1/1000, 0.95))
summ <- data.frame(x,jeffrey_post, uniform_post, step_post)
print(summ)
n <- 116
r <- 17
N <- 1000
prob <- seq(from =0.1, to =N, by=1)/N
like <- dbinom(x=r, size=n, prob)
Uprior <- 1
Bprior <- dbeta(prob, shape1 = 1, shape2 = 4)
Zu <- PartFunc(like*Uprior, 1/N)
Zb <- PartFunc(like*Bprior, 1/N)
Upost <- like*Uprior/Zu
Bpost <- like*Bprior/Zb
Ufirst <- sum(prob*Upost*1/N)
Usecond <- sum(prob*prob*Upost*1/N)
Umax_ind <- which.max(Upost)
Usig <- 1/sqrt(-1*(log(Upost[Umax_ind-1])-2*log(Upost[Umax_ind])+log(Upost[Umax_ind+1]))/(1/(N*N)))
Bfirst <- sum(prob*Bpost*1/N)
Bsecond <- sum(prob*prob*Bpost*1/N)
Bmax_ind <- which.max(Bpost)
Bsig <- 1/sqrt(-1*(log(Bpost[Bmax_ind-1])-2*log(Bpost[Bmax_ind])+log(Bpost[Bmax_ind+1]))/(1/(N*N)))
UGauss <- dnorm(prob, mean =Umax_ind*1/N, sd= Usig)
BGauss <- dnorm(prob, mean =Bmax_ind*1/N, sd= Bsig)
par(mfrow=c(1,2))
plot(prob,Bpost, col="blue",type="l",lwd=2 ,lty=1, xlim=c(0,0.5),xlab = "Probability",ylab = "Probability Density")
abline(v=conf(Bpost,1/1000, 0.95), col=c("blue", "blue"), lty=c(1,1), lwd=c(2, 2))
lines(prob,Upost, col="red",lty=2,lwd=2)
abline(v=conf(Upost,1/1000, 0.95), col=c("red", "red"), lty=c(2,2), lwd=c(2, 2))
legend(x="topright",legend=c("Beta-posterior","Uniform-posterior"), col=c("blue","red"),lty=c(1,2), cex=0.6)
plot(prob,BGauss, col="black",type="l",lwd=2 ,lty=1, xlim=c(0,0.5),xlab = "Probability",ylab = "Probability Density")
abline(v=conf(BGauss,1/1000, 0.95), col=c("black", "black"), lty=c(1,1), lwd=c(2, 2))
lines(prob,UGauss, col="darkgreen",lty=2,lwd=2)
abline(v=conf(UGauss,1/1000, 0.95), col=c("darkgreen", "darkgreen"), lty=c(2,2), lwd=c(2, 2))
legend(x="topright",legend=c("Beta-post Gaussian approx","Unif-post Gaussian approx"), col=c("black","darkgreen"),lty=c(1,2), cex=0.5)
cat("The first and the second moment of the posterior of the unif prior are:", Ufirst,",", Usecond, "\n")
cat("The first and the second moment of the posterior of the beta prior are:", Bfirst," ", Bsecond, "\n")
par(mfrow=c(1,2))
plot(prob,Bpost, col="blue",type="l",lwd=2 ,lty=1, xlim=c(0,0.5),xlab = "Probability",ylab = "Probability Density")
abline(v=conf(Bpost,1/1000, 0.95), col=c("blue", "blue"), lty=c(1,1), lwd=c(2, 2))
lines(prob,BGauss, col="red",lty=2,lwd=2)
abline(v=conf(BGauss,1/1000, 0.95), col=c("red", "red"), lty=c(2,2), lwd=c(2, 2))
legend(x="topright",legend=c("Beta-posterior","Beta-post Gaussian approx"), col=c("blue","red"),lty=c(1,2), cex=0.5)
plot(prob,Upost, col="black",type="l",lwd=2 ,lty=1, xlim=c(0,0.5),xlab = "Probability",ylab = "Probability Density")
abline(v=conf(Upost,1/1000, 0.95), col=c("black", "black"), lty=c(1,1), lwd=c(2, 2))
lines(prob,UGauss, col="darkgreen",lty=2,lwd=2)
abline(v=conf(UGauss,1/1000, 0.95), col=c("darkgreen", "darkgreen"), lty=c(2,2), lwd=c(2, 2))
legend(x="topright",legend=c("Uniform-posterior","Unif-post Gaussian approx"), col=c("black","darkgreen"),lty=c(1,2), cex=0.5)
n <- 30
r <- 15
N <- 1000
prob <- seq(from = 0.1, to = N, by = 1)/N
like <- dbinom(x=r, size=n, prob)
like <- like/PartFunc(like,1/N)
Uprior <- rep(1,N)
Bprior <- dbeta(prob, shape1 = 3, shape2 = 2)
Zu <- PartFunc(like*Uprior, 1/N)
Zb <- PartFunc(like*Bprior, 1/N)
Upost <- like*Uprior/Zu
Bpost <- like*Bprior/Zb
Ufirst <- sum(prob*Upost*1/N)
Usecond <- sum(prob*prob*Upost*1/N)
Bfirst <- sum(prob*Bpost*1/N)
Bsecond <- sum(prob*prob*Bpost*1/N)
par(mfrow=c(1,2))
plot(prob,Bpost, col="blue",type="l",lwd=2 ,lty=1,xlab = "Probability",ylab = "Probability Density")
abline(v=conf(Bpost,1/1000, 0.95), col=c("darkgreen", "darkgreen"), lty=c(1,1), lwd=c(2, 2))
lines(prob,Bprior, col="red",lty=2,lwd=2)
lines(prob,like, col="brown",lty=3,lwd=2)
legend(x="topright",legend=c("Beta-posterior","Beta-prior","Likelihood"), col=c("blue","red","brown"),lty=c(1,2,3), cex=0.5)
plot(prob,Upost, col="black",type="l",lwd=2 ,lty=1,xlab = "Probability",ylab = "Probability Density")
abline(v=conf(Upost,1/1000, 0.95), col=c("darkgreen", "darkgreen"), lty=c(1,1), lwd=c(2, 2))
lines(prob,Uprior, col="red",lty=2,lwd=2)
lines(prob,like, col="brown",lty=3,lwd=2)
legend(x="topright",legend=c("Uniform-posterior","Uniform-prior","Likelihood"), col=c("blue","red","brown"),lty=c(1,2,3), cex=0.5)
cat("The first and the second moment of the posterior of the unif prior are:", Ufirst,",", Usecond, "\n")
cat("The first and the second moment of the posterior of the beta prior are:", Bfirst," ", Bsecond, "\n")
tosses <- c(1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,0, 0)
Uvalues <- c()
Bvalues <- c()
ULowt <- c()
UUpt <- c()
BLowt <- c()
BUpt <- c()
r <- 0
vers1 = FALSE
for (i in 1:length(tosses)){
n <- 1
r <- tosses[i]
N <- 1000
prob <- seq(from = 0.1, to = N, by = 1)/N
like <- dbinom(x=r, size=n, prob)
like <- like/PartFunc(like,1/N)
if (i==1){
Uprior <- 1
Bprior <- dbeta(prob, shape1 = 2, shape2 = 3)
}
Zu <- PartFunc(like*Uprior, 1/N)
Zb <- PartFunc(like*Bprior, 1/N)
Upost <- like*Uprior/Zu
Bpost <- like*Bprior/Zb
Ufirst <- sum(prob*Upost*1/N)
Usecond <- sum(prob*prob*Upost*1/N)
Uvalues <- append(Uvalues, Ufirst)
ULowt <- append(ULowt,conf(Upost,1/N,0.95)[1])
UUpt <- append(UUpt,conf(Upost,1/N,0.95)[2])
Bfirst <- sum(prob*Bpost*1/N)
Bsecond <- sum(prob*prob*Bpost*1/N)
Bvalues <- append(Bvalues, Bfirst)
BLowt <- append(BLowt,conf(Bpost,1/N,0.95)[1])
BUpt <- append(BUpt,conf(Bpost,1/N,0.95)[2])
Uprior <- Upost
Bprior <- Bpost
}
Num_toss <- seq(from=1, to=length(Uvalues), by=1)
plot(Num_toss,Uvalues, col="blue",type="o",lwd=2 ,lty=1, ylim=c(0,1), ylab = "Probability", xlab = "Number of tosses")
arrows(x0=Num_toss, y0=ULowt, x1=Num_toss, y1=UUpt, code=3, angle=90, length=0.1, col = 'blue')
lines(Num_toss,Bvalues, col="red",type="o",lty=2,lwd=2)
arrows(x0=Num_toss, y0=BLowt, x1=Num_toss, y1=BUpt, code=3, angle=90, length=0.1, col = 'red')
legend(x="topright",legend=c("Uniform-prior","Beta-prior"), col=c("blue","red"),lty=c(1,2), cex=0.8)
cat("The result of the sequential analysis is", Bvalues[length(Bvalues)] ,Uvalues[length(Uvalues)], "with respect to 0.5 of a one-step analysis, so obviously they are the same")
mat <- cbind(c(1,1,1,1,1),c(1,1,1,1,0),c(1,1,1,0,0),c(1,1,0,0,0),c(1,0,0,0,0),c(0,0,0,0,0))
box <- sample(1:6,1)
ph_e <- c(1,1,1,1,1,1)/6
ph_et <- c(1,1,1,1,1,1)/6
e <- 40
ex_balls <- c("N")
for (j in 1:e){
ball <- sample(1:5,1)
ext <- mat[ball,box]
if(ext == 1){
ex_balls <- append(ex_balls,"B")
}
else{
ex_balls <- append(ex_balls,"W")
}
for (i in 1:6){
ph_e[i] <- length(mat[,i][mat[,i] == ext])/5 * ph_e[i]
}
ph_e <- ph_e/sum(ph_e)
ph_et <- rbind(ph_et,ph_e)
}
par(mfrow=c(2,3))
Extractions <- seq(from =0, to = e, by=1)
plot(Extractions,ph_et[,1], col="blue",type="l",lwd=2 , ylim=c(0,1) ,lty=1,main = "Box H0", ylab = "Probability")
plot(Extractions,ph_et[,2], col="black",type="l",lwd=2 , ylim=c(0,1),lty=1,main ="Box H1" , ylab = "Probability")
plot(Extractions,ph_et[,3], col="red",type="l",lwd=2 , ylim=c(0,1),lty=1,main ="Box H2", ylab = "Probability" )
plot(Extractions,ph_et[,4], col="darkgreen",type="l",lwd=2 , ylim=c(0,1),lty=1,main = "Box H3", ylab = "Probability")
plot(Extractions,ph_et[,5], col="orange",type="l",lwd=2 , ylim=c(0,1),lty=1,main ="Box H4", ylab = "Probability" )
plot(Extractions,ph_et[,6], col="brown",type="l",lwd=2 , ylim=c(0,1),lty=1,main = "Box H5", ylab = "Probability")
cat("The real box tossed is H",box-1,"\n")
cat("Probabilities of each box at the",e,"th trial is\nH0 =",ph_et[e,1],"\nH1 =",ph_et[e,2],"\nH2 =",ph_et[e,3],"\nH3 =",ph_et[e,4],"\nH4 =",ph_et[e,5],"\nH5 =",ph_et[e,6])
library(tidyverse)
df <- data.frame(round(ph_et,3))
Extraction <- seq(from=0, to=e, by=1)
df <- cbind(df, Extraction)
df <- cbind(df, ex_balls)
df <- rename(df,H0=X1,
H1=X2,
H2=X3,
H3=X4,
H4=X5,
H5=X6,
BALL=ex_balls)
print(df)
conf <- function(x,delta,c){
p <- 0
j <- 0
low <- 0
high <- 0
Z = sum(x*delta)
for (i in x){
p <- p+i*delta/Z
if (p>=(1-c)/2){
low <- j
break
}
j <- j+1
}
p <- 0
j <- 0
for (i in x){
p <- p+i*delta/Z
if (p>=c+(1-c)/2){
high <- j
break
}
j <- j+1
}
return(c(low*delta,high*delta))
}
PartFunc <- function(x,delta){
return(sum(x*delta))
}
median <- function(x,delta){
p <- 0
j <- 0
m <- 0
Z = sum(x*delta)
for (i in x){
p <- p+i*delta/Z
if (p>=0.5){
m <- j
break
}
j <- j+1
}
return(m*delta)
}
y <- c(0, 1 ,2 ,3 ,4, 5)
n1 <- c(109 ,65, 22, 3 ,1 ,0)
n2 <- c(144, 91, 32, 11, 2, 0)
n <- n1 + n2
space <- 0.005
grid <- seq(0,1.5,by=space)
Bpost1 <- dgamma(x = grid,shape = sum(y*n1)+1,rate = sum(n1) )
Bpost2 <- dgamma(x = grid,shape = sum(y*n2)+1,rate = sum(n2) )
Jpost1 <- dgamma(x = grid,shape = sum(y*n1)+1/2,rate = sum(n1) )
Jpost2 <- dgamma(x = grid,shape = sum(y*n2)+1/2,rate = sum(n2) )
mean_b1 <- sum(Bpost1*grid*space)
mean_b2 <- sum(Bpost2*grid*space)
mean_j1 <- sum(Jpost1*grid*space)
mean_j2 <- sum(Jpost2*grid*space)
var_b1 <- sum(Bpost1*grid^2*space) - sum(Bpost1*grid*space)^2
var_b2 <- sum(Bpost2*grid^2*space) - sum(Bpost2*grid*space)^2
var_j1 <- sum(Jpost1*grid^2*space) - sum(Jpost1*grid*space)^2
var_j2 <- sum(Jpost2*grid^2*space) - sum(Jpost2*grid*space)^2
b1sum <- c( mean_b1, var_b1, median(Bpost1,space), conf(Bpost1,space,0.95)[1], conf(Bpost1,space,0.95)[2])
b2sum <- c( mean_b2, var_j2, median(Bpost2,space), conf(Bpost2,space,0.95)[1], conf(Bpost2,space,0.95)[2])
j1sum <- c( mean_j1, var_j1, median(Jpost1,space), conf(Jpost1,space,0.95)[1], conf(Jpost1,space,0.95)[2])
j2sum <- c( mean_j2, var_j2, median(Jpost2,space), conf(Jpost2,space,0.95)[1], conf(Jpost2,space,0.95)[2])
summa <- rbind(b1sum,b2sum,j1sum,j2sum)
rownames(summa) <- c('Uniform, n1 obs','Uniform, n2 obs','Jeffrey, n1 obs','Jeffrey, n2 obs')
colnames(summa) <- c('Mean', 'Variance','Median','Lower bound 95% credibility','Upper bound 95% credibility')
summa <- as.data.frame(round(summa,4))
plot(grid,Bpost1, col="red",type="l",lwd=1 ,lty=2, xlim = c(0.3,1.5), ylim = c(0,max(Bpost1,Bpost2,Jpost1,Jpost2)))
abline(v=conf(Bpost1,space, 0.95), col=c("red", "red"), lty=c(2,2), lwd=c(2, 2))
lines(grid,Bpost2, col="blue",lty=1,lwd=2)
abline(v=conf(Bpost2,space, 0.95), col=c("blue", "blue"), lty=c(3,3), lwd=c(2, 2))
lines(grid,Jpost1, col="darkgreen",lty=1,lwd=2)
abline(v=conf(Jpost1,space, 0.95), col=c("darkgreen", "darkgreen"), lty=c(2,2), lwd=c(2, 2))
lines(grid,Jpost2, col="black",lty=1,lwd=2)
abline(v=conf(Jpost2,space, 0.95), col=c("black", "black"), lty=c(2,2), lwd=c(2, 2))
legend(x="topright",legend=c("Uniform-Posterior, n1 obs","Uniform-Posterior, n2 obs","Jeffrey-Posterior, n1 obs","Jeffrey-Posterior, n2 obs", "95% credibility interval"), col=c("red","blue","darkgreen","black","grey"),lty=c(1,1,1,1,2), cex=0.8)
print(summa)
Bpost_tot <- dgamma(x = grid,shape = sum(y*n)+1,rate = sum(n) )
Jpost_tot <- dgamma(x = grid,shape = sum(y*n)+1/2,rate = sum(n) )
mean_btot <- sum(Bpost_tot*grid*space)
mean_jtot <- sum(Jpost_tot*grid*space)
var_btot <- sum(Bpost_tot*grid^2*space) - sum(Bpost_tot*grid*space)^2
var_jtot <- sum(Jpost_tot*grid^2*space) - sum(Jpost_tot*grid*space)^2
plot(grid,Bpost_tot, col="red",type="l",lwd=2 ,lty=2, xlim = c(0,1.5), ylim = c(0,max(Bpost_tot,Jpost_tot)))
abline(v=conf(Bpost_tot,space, 0.95), col=c("red", "red"), lty=c(2,2), lwd=c(2, 2))
lines(grid,Jpost_tot, col="blue",lty=1,lwd=2)
abline(v=conf(Jpost_tot,space, 0.95), col=c("blue", "blue"), lty=c(3,3), lwd=c(2, 2))
bsum <- c( mean_btot, var_btot, median(Bpost_tot,space), conf(Bpost_tot,space,0.95)[1], conf(Bpost_tot,space,0.95)[2])
jsum <- c( mean_jtot, var_jtot, median(Jpost_tot,space), conf(Jpost_tot,space,0.95)[1], conf(Jpost_tot,space,0.95)[2])
summa <- rbind(bsum,jsum)
rownames(summa) <- c('Uniform','Jeffrey')
colnames(summa) <- c('Mean', 'Variance','Median','Lower bound 95% credibility','Upper bound 95% credibility')
summa <- as.data.frame(round(summa,4))
print(summa)
metropolis.1dim <- function(func, mu_0, n_samp, sig) {
mu <- mu_0
n_acc <- 0
chain <- c()
samples <- c()
chain <- append(chain,mu)
for (i in 1:n_samp){
new_mu <- rnorm(n=1, mu, sig)
bound <- min(func(new_mu)/func(mu),1)
dice <- runif(1,0,1)
if(dice<bound){
mu <- new_mu
chain <- append(chain,mu)
samples <- append(samples,mu)
n_acc <- n_acc +1
}
else{
samples <- append(samples,mu)
chain <- append(chain,mu)
}
}
results <- list("samples" =samples, "rate"=n_acc/n_samp, "chain"=chain)
return( results )
}
Unif_post <- function(x){
return(dgamma(x=x ,shape = sum(y*n)+1,rate = sum(n)))
}
Jeffrey_post <- function(x){
return(dgamma(x=x,shape = sum(y*n)+1/2,rate = sum(n)))
}
cumlative_hist <- function(h,c){
h$counts <- cumsum(h$counts)
h$counts <- h$counts/h$counts[length(h$counts)]
bin <-c()
for (i in 1:length(h$counts)){
if (h$counts[i] >= (1-c)/2){
bin <- append(bin,i)
break
}
}
for (i in 1:length(h$counts)){
if (h$counts[i] >= c+(1-c)/2){
bin <- append(bin,i)
break
}
}
return(c(h$breaks[bin[1]],h$breaks[bin[2]]))
}
conf_tails <- function(x,delta,c,tail) {
if(tail=="lower"){
p <- 0
j <- 0
val <- 0
val <- 0
Z = sum(x*delta)
for (i in x){
p <- p+i*delta/Z
if (p>=(1-c)){
val <- j
break
}
j <- j+1
}
}
else if(tail=="higher"){
p <- 0
j <- 0
val <- 0
val <- 0
Z = sum(x*delta)
for (i in x){
p <- p+i*delta/Z
if (p>=c){
val <- j
break
}
j <- j+1
}
}
return(val*delta)
}
mcmcu <- metropolis.1dim(Unif_post,1,100000,0.5)
mcmcj <- metropolis.1dim(Jeffrey_post,1,100000,0.5)
h <- hist(mcmcu$samples,breaks=200,plot = FALSE)
h$counts <- h$counts/length(h$counts)
plot(h, ylim= c(0,13), main = 'Histogram of the MCMC result, Uniform prior')
lines(grid,Unif_post(grid))
plot(seq(1,100001,by=1),mcmcu$chain, type="l", xlab = "iterations", ylab = "chain positions", main = "MCMC chain")
plot(acf(mcmcu$chain, lag.max = 500, plot = FALSE)$acf, ylab = "ACF", xlab = "Lags", main="ACF function")
bsum <- c( mean_btot, var_btot, median(Bpost_tot,space), conf(Bpost_tot,space,0.95)[1], conf(Bpost_tot,space,0.95)[2])
mcmcsum <- c( mean(mcmcu$samples), sd(mcmcu$samples)^2, cumlative_hist(h,0)[1], cumlative_hist(h,0.95)[1], cumlative_hist(h,0.95)[2])
summa <- rbind(bsum,mcmcsum)
rownames(summa) <- c('By integration','MCMC procedure')
colnames(summa) <- c('Mean', 'Variance','Median','Lower bound 95% credibility','Upper bound 95% credibility')
summa <- as.data.frame(round(summa,4))
print(summa)
h <- hist(mcmcj$samples,breaks=200,plot = FALSE)
h$counts <- h$counts/length(h$counts)
plot(h, ylim= c(0,13), main = 'Histogram of the MCMC result, Uniform prior')
lines(grid,Jeffrey_post(grid))
plot(seq(1,100001,by=1),mcmcj$chain, type="l", xlab = "iterations", ylab = "chain positions", main='MCMC chain')
plot(acf(mcmcj$chain, lag.max = 500, plot = FALSE)$acf, ylab = "ACF", xlab = "Lags", main= 'ACF function')
jsum <- c( mean_btot, var_btot, median(Bpost_tot,space), conf(Bpost_tot,space,0.95)[1], conf(Bpost_tot,space,0.95)[2])
mcmcsum <- c( mean(mcmcu$samples), sd(mcmcu$samples)^2, cumlative_hist(h,0)[1], cumlative_hist(h,0.95)[1], cumlative_hist(h,0.95)[2])
summa <- rbind(jsum,mcmcsum)
rownames(summa) <- c('By integration','MCMC procedure')
colnames(summa) <- c('Mean', 'Variance','Median','Lower bound 95% credibility','Upper bound 95% credibility')
summa <- as.data.frame(round(summa,4))
print(summa)
n <- 116
r <- 11
N <- 1000
prob <- seq(from =0.01, to =N, by=1)/N
pe <- r/n
cat("For the frequentist approach p is:",pe)
bprior <- dbeta(prob, shape1 = 1, shape2 = 10)
like <- dbinom(x=r, size=n, prob)
Z <- PartFunc(like*bprior,1/N)
Bpost <- like*bprior/Z
cat("\nthe bayesian estimator for p is:",which.max(Bpost)*1/N, "\nthe mean and variance are:",sum(prob*Bpost*1/N),sum(prob*prob*Bpost*1/N), "\nthe 95% credibility interval is:", conf(Bpost,1/N,0.95) )
plot(prob,Bpost, type = "l", xlim= c(0,0.3), col="blue")
abline(v=c(which.max(Bpost)*1/N,sum(prob*Bpost*1/N),conf(Bpost,1/N,0.95)), col= c("black","red","darkgreen","darkgreen"))
legend(x="topright",legend=c("Posterior","Max","Mean", "95% credibility interval"), col=c("blue","black","red","darkgreen"),lty=c(1,1,1,1), cex=0.8)
real_freq <- rbinom(n=1000000, size=n, 0.1)
h <- hist(real_freq, breaks = max(real_freq) ,plot=FALSE)
h$counts <- cumsum(h$counts)
h$counts <- h$counts/h$counts[length(h$counts)]
plot(h, col = "lightblue", xaxt="n" ,xlim=c(-1,max(real_freq)), main = "Cumulative Function of Binomial (size=116,0.1)")
axis(side=1,at=h$mids,labels=seq(min(real_freq),max(real_freq)-1))
axis(side=2,at=seq(-1,1,0.1),labels=seq(-1,1,0.1))
abline(h=0.05, col="black", lty=2, lwd= 2)
cat("The null hypothsis of p= 0.1 is accepted, because we can see that 11 extractions over 116 trial is inside the 95% confidence level, because it is above the vertical line drawn at 0.05")
print(conf_tails(Bpost, 1/N, 0.95 ,"higher"))
n <- 165
r <- 9
pe <- r/n
cat("For the frequentist approach p is:",pe)
bprior <- dbeta(prob, shape1 = 1, shape2 = 10)
prevprior <- Bpost
like <- dbinom(x=r, size=n, prob)
Zb <- PartFunc(like*bprior,1/N)
Zp <- PartFunc(like*prevprior,1/N)
Bpost <- like*bprior/Z
Ppost <- like*prevprior/Zp
cat("\nWith a Beta(1,10) prior")
cat("\nthe bayesian estimator for p is:",which.max(Bpost)*1/N, "\nthe mean and variance are:",sum(prob*Bpost*1/N),sum(prob*prob*Bpost*1/N)-sum(prob*Bpost*1/N)*sum(prob*Bpost*1/N), "\nthe 95% credibility interval is:", conf(Bpost,1/N,0.95),"\n" )
cat("\nWith the prior as the last posterior")
cat("\nthe bayesian estimator for p is:",which.max(Ppost)*1/N, "\nthe mean and variance are:",sum(prob*Ppost*1/N),sum(prob*prob*Ppost*1/N)-sum(prob*Ppost*1/N)*sum(prob*Ppost*1/N), "\nthe 95% credibility interval is:", conf(Ppost,1/N,0.95) )
plot(prob,Bpost, type = "l", xlim= c(0,0.2), col="blue", lwd=2, main= "Post With beta prior" )
abline(v=c(which.max(Bpost)*1/N,sum(prob*Bpost*1/N),conf(Bpost,1/N,0.95)), col= c("black","red","darkgreen","darkgreen"),lwd=c(2,2,2,2))
plot(prob,Ppost, type = "l", xlim= c(0,0.2), col="blue", lwd=2, main = "Post With prior = last posterior" )
abline(v=c(which.max(Ppost)*1/N,sum(prob*Ppost*1/N),conf(Ppost,1/N,0.95)), col= c("black","red","darkgreen","darkgreen"), lwd=c(2,2,2,2))
real_freq <- rbinom(n=1000000, size=n, 0.1)
h <- hist(real_freq, breaks = max(real_freq) ,plot=FALSE)
h$counts <- cumsum(h$counts)
h$counts <- h$counts/h$counts[length(h$counts)]
plot(h, col = "lightblue", xaxt="n" ,xlim=c(-1,max(real_freq)), main = "Cumulative Function of Binomial (size=165,p=0.1)")
axis(side=1,at=h$mids,labels=seq(min(real_freq),max(real_freq)-1))
axis(side=2,at=seq(-1,1,0.1),labels=seq(-1,1,0.1))
abline(h=0.05, col="black", lty=2, lwd= 2)
cat("The null hypothsis of p= 0.15 is accepted, because we can see that 6 extractions over 75 trial is inside the 95% confidence level, because it is above the vertical line drawn at 0.05, so the new method is not better than the old one")
print(conf_tails(Bpost, 1/N, 0.95 ,"higher" ))
print(conf_tails(Ppost, 1/N, 0.95 ,"higher" ))
print(conf(Ppost, 1/N, 0.95))
library(coda)
library(rjags)
model <- "model{
# Likelihood
y ~ dbinom(theta, n)
# Prior
theta ~ dbeta(1, 1)
}"
datalist <- list(y= 9, n= 165)
jm <- jags.model(file= textConnection(model), data= datalist, n.chains = 5)
update(jm, n.iter = 1000)
Nrep = 1000000 # number of values to simulate
posterior_sample <- coda.samples(jm,
variable.names = c("theta"),
n.iter = Nrep)
summary(posterior_sample)
plot(posterior_sample)
real_freq <- rbinom(n=1000000, size=n, 0.1)
h <- hist(real_freq, breaks = max(real_freq) ,plot=FALSE)
h$counts <- cumsum(h$counts)
h$counts <- h$counts/h$counts[length(h$counts)]
plot(h, col = "lightblue", xaxt="n" ,xlim=c(-1,max(real_freq)), main = "Cumulative Function of Binomial (size=116,0.1)")
axis(side=1,at=h$mids,labels=seq(min(real_freq),max(real_freq)-1))
axis(side=2,at=seq(-1,1,0.1),labels=seq(-1,1,0.1))
abline(h=0.05, col="black", lty=2, lwd= 2)
cat("The null hypothsis of p= 0.1 is accepted, because we can see that 11 extractions over 116 trial is inside the 95% confidence level, because it is above the vertical line drawn at 0.05")
print(conf_tails(Bpost, 1/N, 0.95 ,"higher"))
n <- 165
r <- 9
pe <- r/n
cat("For the frequentist approach p is:",pe)
bprior <- dbeta(prob, shape1 = 1, shape2 = 10)
prevprior <- Bpost
like <- dbinom(x=r, size=n, prob)
Zb <- PartFunc(like*bprior,1/N)
Zp <- PartFunc(like*prevprior,1/N)
Bpost <- like*bprior/Z
Ppost <- like*prevprior/Zp
cat("\nWith a Beta(1,10) prior")
cat("\nthe bayesian estimator for p is:",which.max(Bpost)*1/N, "\nthe mean and variance are:",sum(prob*Bpost*1/N),sum(prob*prob*Bpost*1/N)-sum(prob*Bpost*1/N)*sum(prob*Bpost*1/N), "\nthe 95% credibility interval is:", conf(Bpost,1/N,0.95),"\n" )
cat("\nWith the prior as the last posterior")
cat("\nthe bayesian estimator for p is:",which.max(Ppost)*1/N, "\nthe mean and variance are:",sum(prob*Ppost*1/N),sum(prob*prob*Ppost*1/N)-sum(prob*Ppost*1/N)*sum(prob*Ppost*1/N), "\nthe 95% credibility interval is:", conf(Ppost,1/N,0.95) )
plot(prob,Bpost, type = "l", xlim= c(0,0.2), col="blue", lwd=2, main= "Post With beta prior" )
abline(v=c(which.max(Bpost)*1/N,sum(prob*Bpost*1/N),conf(Bpost,1/N,0.95)), col= c("black","red","darkgreen","darkgreen"),lwd=c(2,2,2,2))
plot(prob,Ppost, type = "l", xlim= c(0,0.2), col="blue", lwd=2, main = "Post With prior = last posterior" )
abline(v=c(which.max(Ppost)*1/N,sum(prob*Ppost*1/N),conf(Ppost,1/N,0.95)), col= c("black","red","darkgreen","darkgreen"), lwd=c(2,2,2,2))
real_freq <- rbinom(n=1000000, size=n, 0.1)
h <- hist(real_freq, breaks = max(real_freq) ,plot=FALSE)
h$counts <- cumsum(h$counts)
h$counts <- h$counts/h$counts[length(h$counts)]
plot(h, col = "lightblue", xaxt="n" ,xlim=c(-1,max(real_freq)), main = "Cumulative Function of Binomial (size=165,p=0.1)")
axis(side=1,at=h$mids,labels=seq(min(real_freq),max(real_freq)-1))
axis(side=2,at=seq(-1,1,0.1),labels=seq(-1,1,0.1))
abline(h=0.05, col="black", lty=2, lwd= 2)
cat("The null hypothsis of p= 0.15 is accepted, because we can see that 6 extractions over 75 trial is inside the 95% confidence level, because it is above the vertical line drawn at 0.05, so the new method is not better than the old one")
print(conf_tails(Bpost, 1/N, 0.95 ,"higher" ))
print(conf_tails(Ppost, 1/N, 0.95 ,"higher" ))
print(conf(Ppost, 1/N, 0.95))
library(coda)
library(rjags)
model <- "model{
# Likelihood
y ~ dbinom(theta, n)
# Prior
theta ~ dbeta(1, 1)
}"
datalist <- list(y= 9, n= 165)
jm <- jags.model(file= textConnection(model), data= datalist, n.chains = 5)
update(jm, n.iter = 1000)
Nrep = 1000000 # number of values to simulate
posterior_sample <- coda.samples(jm,
variable.names = c("theta"),
n.iter = Nrep)
summary(posterior_sample)
plot(posterior_sample)
